{"date": null, "title": "Principal Data Engineer - Remote US", "company": "Seamless.AI", "job_apply_link": "https://www.theladders.com/job/principal-data-engineer-remote-us-seamlessai-virtual-travel_74427107?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic", "company_url": "https://seamless.ai", "company_type": null, "job_type": "Full-time", "job_is_remote": "Remote", "job_offer_expiration_date": null, "salary_low": 140940, "salary_high": 195148, "salary_currency": null, "salary_period": "YEAR", "job_benefits": null, "city": null, "state": null, "country": null, "apply_options": "https://www.theladders.com/job/principal-data-engineer-remote-us-seamlessai-virtual-travel_74427107?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic\nhttps://aijobs.net/job/1040757-principal-data-engineer-remote-us/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic\nhttps://www.careervault.io/remote/seamless-ai-26190/data/principal-data-engineer-remote-us-united-states-5170178?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic\nhttps://www.ziprecruiter.com/c/Seamless.AI/Job/Principal-Data-Engineer-Remote-US/-in-Remote,US?jid=1287315855cabe35&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic\nhttps://www.remotefront.com/remote-jobs/seamless-ai-principal-data-engineer-remote-us-er2d1?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic", "required_skills": null, "required_experience": "", "required_education": "", "description": "The Opportunity:\n\nAt Seamless.AI, we're seeking a highly skilled and experienced Principal Data Engineer with expertise in Python, Spark, AWS Glue, and other ETL (Extract, Transform, Load) technologies. The ideal candidate will have a proven track record in data acquisition and transformation, as well as experience working with large data sets and applying methodologies for data matching and aggregation. Strong organizational skills and the ability to work independently as a self-starter are essential for this role.\nResponsibilities:\n\u2022 Design, develop, and maintain robust and scalable ETL pipelines to acquire, transform, and load data from various sources into our data ecosystem.\n\u2022 Collaborate with cross-functional teams to understand data requirements and develop efficient data acquisition and integration strategies.\n\u2022 Implement data transformation logic using Python and other relevant programming languages and frameworks.\n\u2022 Utilize AWS Glue or similar tools to create and manage ETL jobs, workflows, and data catalogs.\n\u2022 Optimize and tune ETL processes for improved performance and scalability, particularly with large data sets.\n\u2022 Apply methodologies and techniques for data matching, deduplication, and aggregation to ensure data accuracy and quality.\n\u2022 Implement and maintain data governance practices to ensure compliance, data security, and privacy.\n\u2022 Collaborate with the data engineering team to explore and adopt new technologies and tools that enhance the efficiency and effectiveness of data processing.\n\nSkillset:\n\u2022 Strong proficiency in Python and experience with related libraries and frameworks (e.g., pandas, NumPy, PySpark).\n\u2022 Hands-on experience with AWS Glue or similar ETL tools and technologies.\n\u2022 Solid understanding of data modeling, data warehousing, and data architecture principles.\n\u2022 Expertise in working with large data sets, data lakes, and distributed computing frameworks.\n\u2022 Experience developing and training machine learning models.\n\u2022 Strong proficiency in SQL.\n\u2022 Familiarity with data matching, deduplication, and aggregation methodologies.\n\u2022 Experience with data governance, data security, and privacy practices.\n\u2022 Strong problem-solving and analytical skills, with the ability to identify and resolve data-related issues.\n\u2022 Excellent communication and collaboration skills, with the ability to work effectively in cross-functional teams.\n\u2022 Highly organized and self-motivated, with the ability to manage multiple projects and priorities simultaneously.\nEducation and Requirements:\n\u2022 Bachelor's degree in Computer Science, Information Systems, related fields or equivalent years of work experience.\n\u2022 7+ years of experience as a Data Engineer, with a focus on ETL processes and data integration.\n\u2022 Professional experience with Spark and AWS pipeline development required.\nCheck out what our employees think about working at Seamless: CLICK HERE\n\nSeamless.AI has been delivering the world's best sales leads since 2015. Our product is the first real time, B2B search engine helping sales teams maximize revenue, increase sales, and easily acquire their total addressable market using artificial intelligence. Our product has been recognized by G2 in 2024 in the following categories: Best Software Products Overall, Best Software Products for Small Business, and Highest Satisfaction Products. We have been recognized as one of Ohio's fastest growing companies and won 2020 Best Places to Work, LinkedIn's Top 50 Tech Startups in 2020,2022, and 2023, Purpose Jobs 2023 Best Workplace Culture and Best Work-life balance, and Purpose Jobs best place to work in 2024. We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Visa Sponsorship is not included in our hiring package. Applicants will need to be authorized to work in the U.S.", "highlights": "", "resume_similarity": 0.5251441558870509}