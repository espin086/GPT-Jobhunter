{"date": null, "title": "Principal MLOPs Engineer\u200b/Canada", "company": "Karkidi", "job_apply_link": "https://www.learn4good.com/jobs/online_remote/info_technology/3985005341/e/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic", "company_url": "https://www.karkidi.com", "company_type": null, "job_type": "Full-time", "job_is_remote": "Remote", "job_offer_expiration_date": null, "salary_low": null, "salary_high": null, "salary_currency": null, "salary_period": null, "job_benefits": null, "city": "San Antonio", "state": "Texas", "country": "US", "apply_options": "https://www.learn4good.com/jobs/online_remote/info_technology/3985005341/e/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic", "required_skills": null, "required_experience": "", "required_education": "", "description": "Position: Principal MLOPs Engineer (Canada)\n\nAbout the Role:\n\nWe are looking for a seasoned Principal ML OPS Engineer to architect, build, and optimize ML inference platform. The role demands an individual with significant expertise in Machine Learning engineering and infrastructure, with an emphasis on building Machine Learning inference systems. Proven experience in building and scaling ML inference platforms in a production environment is crucial. This remote position calls for exceptional communication skills and a knack for independently tackling complex challenges with innovative solutions.\n\nWhat you will be doing:\n\u2022 Architect and optimize our existing data infrastructure to support cutting-edge machine learning and deep learning models.\n\u2022 Collaborate closely with cross-functional teams to translate business objectives into robust engineering solutions.\n\u2022 Own the end-to-end development and operation of high-performance, cost-effective inference systems for a diverse range of models, including state-of-the-art LLMs.\n\u2022 Provide technical leadership and mentorship to foster a high-performing engineering team.\n\nRequirements:\n\u2022 Proven track record in designing and implementing cost-effective and scalable ML inference systems.\n\u2022 Hands-on experience with leading deep learning frameworks such as Tensor Flow, Keras, or Spark MLlib.\n\u2022 Solid foundation in machine learning algorithms, natural language processing, and statistical modeling.\n\u2022 Strong grasp of fundamental computer science concepts including algorithms, distributed systems, data structures, and database management.\n\u2022 Proficiency and recent experience in Java is required (Must have).\n\u2022 Ability to tackle complex challenges and devise effective solutions. Use critical thinking to approach problems from various angles and propose innovative solutions.\n\u2022 Worked effectively in a remote setting, maintaining strong written and verbal communication skills. Collaborate with team members and stakeholders, ensuring clear understanding of technical requirements and project goals.\n\u2022 Proven experience in Apache Hadoop ecosystem (Oozie, Pig, Hive, Map Reduce).\n\u2022 Expertise in public cloud services, particularly in GCP and Vertex AI.\n\nMust have:\n\u2022 Proven expertise in applying model optimization techniques (distillation, quantization, hardware acceleration) to production environments.\n\u2022 Proficiency and recent experience in Java is required (Must have).\n\u2022 In-depth understanding of LLM architectures, parameter scaling, and deployment trade-offs.\n\u2022 Technical degree:\nBachelor's degree in Computer Science with a minimum of 10+ years of relevant industry experience, or a Master's degree in Computer Science with at least 8+ years of relevant industry experience.\n\u2022 A specialization in Machine Learning is preferred.\n\nAbout Rackspace Technology\n\nWe are the multicloud solutions experts. We combine our expertise with the world\u2019s leading technologies \u2014 across applications, data and security \u2014 to deliver end-to-end solutions. We have a proven record of advising customers based on their business challenges, designing solutions that scale, building and managing those solutions, and optimizing returns into the future. Named a best place to work, year after year according to Fortune, Forbes and Glassdoor, we attract and develop world-class talent.\n\nJoin us on our mission to embrace technology, empower customers and deliver the future.\n#J-18808-Ljbffr", "highlights": "\nQualifications:\n Proven experience in building and scaling ML inference platforms in a production environment is crucial, Proven track record in designing and implementing cost-effective and scalable ML inference systems, Hands-on experience with leading deep learning frameworks such as Tensor Flow, Keras, or Spark MLlib, Solid foundation in machine learning algorithms, natural language processing, and statistical modeling, Strong grasp of fundamental computer science concepts including algorithms, distributed systems, data structures, and database management, Proficiency and recent experience in Java is required (Must have), Ability to tackle complex challenges and devise effective solutions, Use critical thinking to approach problems from various angles and propose innovative solutions, Collaborate with team members and stakeholders, ensuring clear understanding of technical requirements and project goals, Proven experience in Apache Hadoop ecosystem (Oozie, Pig, Hive, Map Reduce), Expertise in public cloud services, particularly in GCP and Vertex AI, Proven expertise in applying model optimization techniques (distillation, quantization, hardware acceleration) to production environments, Proficiency and recent experience in Java is required (Must have), In-depth understanding of LLM architectures, parameter scaling, and deployment trade-offs, Technical degree:, Bachelor's degree in Computer Science with a minimum of 10+ years of relevant industry experience, or a Master's degree in Computer Science with at least 8+ years of relevant industry experience, \nResponsibilities:\n We are looking for a seasoned Principal ML OPS Engineer to architect, build, and optimize ML inference platform, The role demands an individual with significant expertise in Machine Learning engineering and infrastructure, with an emphasis on building Machine Learning inference systems, This remote position calls for exceptional communication skills and a knack for independently tackling complex challenges with innovative solutions, Architect and optimize our existing data infrastructure to support cutting-edge machine learning and deep learning models, Collaborate closely with cross-functional teams to translate business objectives into robust engineering solutions, Own the end-to-end development and operation of high-performance, cost-effective inference systems for a diverse range of models, including state-of-the-art LLMs, Provide technical leadership and mentorship to foster a high-performing engineering team, Worked effectively in a remote setting, maintaining strong written and verbal communication skills", "resume_similarity": 0.4640441558450179}